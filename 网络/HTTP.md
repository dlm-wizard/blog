
# HTTP 协议详解
							
## 一：五层网络模型
       每层都是为了完成一种功能。为了实现，大家都得遵守协议。下层都为上层提供服务，上层可以使用所有下层的服务
       
        ├── 应用层「数据传输格式 [应用区分]」
        |    ├ http
        |    ├ ftp
        ├── 传输层「端到端通信 [socket = 主机 + 端口]」       数据：Segment（报文段）
        |    ├ tcp
        |    ├ udp
        ├── 网络层「ip地址 [寻址，区分子网络]」                数据：Packet（数据包）
        ├── 数据链路层「解读方式 [分组]」                     数据：Frame（帧）
        ├── 物理层「物理手段 [电器特性-0、1]」
	
	
### 1.1  网络层的由来
以太网协议，根据 MAC 地址发送数据 [单单依靠技术，上海的网卡找到洛杉矶的网卡，技术上是可以实现的...]
但问题是，以太网采用广播「ARP 协议」的方式发送数据包,每台计算机都收到所有包...


### 1.2 IP 协议的作用：主机到主机

* 一个是为每一台计算机分配 IP 地址
* 另一个是确定哪些地址在同一个子网络「子网掩码」 => 又可以愉快的广播了


#
### 1.3 TCP 和 UDP 的特点

网络层只把分组发送到目的主机，但是真正通信的并不是主机而是主机中的进程。传输层提供了进程间的逻辑通信，传输层向高层用户屏蔽了下面网络层的核心细节，使应用程序看起来像是在两个传输层实体之间有一条端到端的逻辑通信信道。

```bash
# 用户数据报协议 UDP（User Datagram Protocol）
是无连接的，尽最大可能交付，没有拥塞控制，面向报文（对于应用程序传下来的报文不合并也不拆分，只是添加 UDP 首部），支持一对一、一对多、多对一和多对多的交互通信。

1. 能从多个客户端收集数据包，无连接开销很小
2. 可以进行广播和组播处理
```


```bash
# 传输控制协议 TCP（Transmission Control Protocol）
是面向连接的，有流量控制，拥塞控制，提供全双工通信，提供可靠交付，面向字节流（把应用层传下来的报文看成字节流，把字节流组织成大小不等的数据块），每一条 TCP 连接只能是点对点的（一对一）。
```

#### 滑动窗口协议

```bash
滑动窗口协议允许发送方发送多个分组而不需要等待确认，未被确认的分组数 <= N [已发送未确认+允许但尚未发送=窗口大小]
发送方有一个序号范围。基序号（base）定义为最早的未被确认的分组序号，下一个序号（next）定义为最小的未使用的序号。
[base,next-1]已发送未确认分组，[next,base+N-1]内的序号可用于那些要被立即发送的分组，其数据来自上层。
大于base+N-1只有在之前序号被确认后才能使用

发送窗口: 未确认分组限制窗口[start]
接收窗口: 最大有序字节限制窗口[start]
```

#### 流量控制
```bash
# 流量控制是为了控制发送方发送速率，保证接收方来得及接收

接收方发送的确认报文中的窗口字段可以用来控制发送方窗口大小
```

#### TCP 拥塞控制

> TCP 主要通过四个算法来进行拥塞控制：慢开始、拥塞避免、快重传、快恢复

同流量控制比较
```bash
相同：控制发送方的速率

不同：
* 流量控制 -> 接收方能来得及接
* 拥塞控制 -> 降低整个网络的拥塞程度
```

```bash
# 控制发送方的速率

如果网络出现拥塞，分组将会丢失，此时发送方会继续重传，从而导致网络拥塞程度更高
```

#### 慢开始、拥塞避免

![慢开始、拥塞避免](https://github.com/CyC2018/CS-Notes/raw/master/notes/pics/910f613f-514f-4534-87dd-9b4699d59d31.png)

```bash
# 假设
1. 接收方有足够大的接收缓存，不会发生流量控制
2. 虽然 TCP 的窗口基于字节，但是这里设窗口的大小单位为报文段

# cwnd[拥塞窗口] 与 ssthresh[拥塞窗口最大值]
1. 慢开始，令 cwnd = 1，发送方只能发送 1 个报文段；当收到确认后，将 cwnd 加倍，因此之后发送方能够发送的报文段数量为：2、4、8 ...
慢开始门限 ssthresh：
慢开始每个轮次都将 cwnd 加倍，这样会让 cwnd 增长速度非常快，从而使得发送方发送的速度增长速度过快，网络拥塞的可能性也就更高。设置一个慢开始门限 ssthresh 值，当 cwnd >= ssthresh 时，进入拥塞避免，每个轮次只将 cwnd 加 1

2. 如果出现了超时，则令 ssthresh = cwnd / 2，然后重新执行慢开始。
```

#### 快重传、快恢复

![快重传与快恢复](https://github.com/CyC2018/CS-Notes/raw/master/notes/pics/f61b5419-c94a-4df1-8d4d-aed9ae8cc6d5.png)

```bash
在接收方，要求每次接收到报文段都应该对最后一个已收到的有序报文段进行确认

1. 发送方，如果收到三个重复确认，那么可以知道下一个报文段丢失，此时执行快重传，立即重传下一个报文段。
   例如收到三个 M2，则 M3 丢失，立即重传 M3。

# 直接进入拥塞避免
在此情况下，只是丢失个别报文段，而不是网络拥塞。因此执行快恢复，令 ssthresh = cwnd / 2 ，cwnd = ssthresh

# 慢开始和快恢复的快慢指的是 cwnd 的设定值，而不是增长速率
慢开始： cwnd 设定为 1
快恢复： cwnd 设定为 ssthresh
```


* TCP 协议面向有连接(主要是因为有确认机制)，能正确处理丢包「ACK」，传输顺序错乱的问题「SYN」，但是为了建立与断开连接，需要至少7次的发包收包，资源浪费
* UDP 面向无连接，不管对方有没有收到


#### socket 原理

套接字（socket）
是支持TCP/IP协议的端点抽象表示，是一组接口，将复杂的TCP/IP协议族隐藏在socket接口后面

对用户来说，一组简单的接口就是全部，让socket去组织数据，以符合指定的协议。

```bash
# 包含进行网络通信必须的五种信息

1. 连接使用的协议「tcp/udp」
2. 本地主机IP
3. 本机进程的协议端口
4. 目的主机IP
5. 目的进程的协议端口

```
	      
建立 Socket 连接至少需要一对套接字，其中一个运行于客户端「ClientSocket」，另一个运行于服务器端「ServerSocket 」
1. 监听「listen()」：处于等待连接的状态
2. 请求「connect()」：指客户端的套接字提出连接请求，要连接的目标是服务器端的套接字
3. 连接确认「accept()+read/write()」：服务器端接收到了请求，响应客户端的请求，建立新的线程，将服务器端套接字描述发给客户端「」
	  

## 二、http(HyperText Transfer Protocol) 协议「使用 tcp 协议」

HTTP（超文本传输协议）是应用层上的一种客户端/服务端模型的通信协议,它由请求和响应构成，且是无状态的「非 http2」

#### 登录问题

```bash
# 无状态就是在两次请求之间服务器并不会保存任何的数据。

1. 登录就是用某种方法让服务器在多次请求之间能够识别出你
而不是每次发请求都得带上用户名密码这样的识别身份的信息。从登录成功到登出的这个过程，服务器一直维护了一个可以识别出用户信息的数据结构，

2. 广义上来说，这个过程就叫做session，也就是保持了一个会话
```

#### session

一般网站都是记录session.....，但是现在更趋向于stateless。服务器端不维护回话状态(session或成为state)，更有利于服务的横向扩展。
JWT(JSON Web Token)的认证方式更为流行，已经是业界标准了
```bash
# 广义的session
从登录成功到登出的过程，在这个过程中客户端和服务器端维持了保持登录的状态，至于具体怎么维持住这种登录的状态，没有要求。

# 狭义的session
狭义的session就是登录成功后，服务器端存储了一些必须的用户信息，这部分存在服务器端的用户信息就叫做session
```

#### 服务器session+客户端sessionId

> 狭义的session

![广义的session](https://pic4.zhimg.com/v2-dbd12a1c36f22bb160a501848678447b_b.jpg)

```bash
1. 客户端带着用户名和密码去访问 /login 接口，服务器端收到后校验用户名和密码，校验正确就会在服务器端存储一个sessionId和session的映射关系

2. 服务器端返回response，并且将sessionId以set-cookie的方式种在客户端。这里要注意的是，将sessionId存在cookie并不是一种强制的方案，而是大家一般都这么做，而且发请求的时候符合domain和path的时候，会自动带上cookie，省去了手动塞的过程。

3. 客户端发起非登录请求时，服务端通过cookie中的sessionId找到对应的session来知道此次请求是谁发出的。
```

![sessionId和session的映射关系](https://pic4.zhimg.com/v2-72314ca232599fd5eb7440a1c3f41d2b_b.jpg)

#### session 的问题

```bash
# session方式由于会在服务器端维护session信息

1. 单机还好说，如果是多机的话，服务器之间需要同步session信息，服务横向扩展不方便
   横向扩展: 您必须提供一个单独的中央会话存储系统，您的所有应用程序服务器都可以访问该系统

2. session数量随着登录用户的增多而增多，存储会增加很多 [开销太大]
3. session+cookie里面存sessionId的方式可能会有csrf攻击的问题，常见的方式是使用csrf_token来解决
```

#
#### token

跟第一种登录方式sessionId的最本质的区别是：无状态身份验证机制 [通过解析token的计算时间换取了session的存储空间，轻量级]

```bash
# sessionId的方式
本质是把用户状态信息维护在server端

# token
本质是把用户的状态信息加密成一串token传给前端，然后每次发请求时把token带上，传回给服务器端；服务器端收到请求之后，解析token并且验证相关信息；
```

#### token 的组成
```bash
header 头部
{
  "alg": "HS256",
  "typ": "JWT"
}
payload 负载
{
  "sub": "1234567890",
  "name": "John Doe",
  "iat": 1516239022,/*限制一个用户只能登陆一次*/
  "exp": 1555341649998
}
signature 签名

1. header里面描述加密算法和token的类型，类型一般都是JWT
2. payload里面放的是用户的信息，也就是第一种登录方式中需要维护在服务器端session中的信息
3. signature是对前两部分的签名，也可以理解为加密；实现需要一个密钥（secret），这个secret只有服务器才知道
   --> 服务器端用自己的密钥解析token，如果能解析就是自己认证的用户

# 使用header里面的算法按照如下方法来加密
jwt = 算法(base64url(header) + "." + base64url(payload) + "." + signaturejwt)

# 总之，最后的 可以放在response中返回，也可以放在cookie中返回，这都是具体的返回方式，并不重要
```

#### 请求与响应

```bash
# response
拿到Token之后保存(一般放在Local Storage里)，每次向服务器端发送请求都会在Request的Header里面带上


# 客户端发起请求时
官方推荐放在HTTP header中：Authorization: Bearer <token>

这样子确实也可以解决cookie跨域的问题，不过具体放在哪儿还是根据业务场景来定，并没有一定之规。

# 限制一个用户只能登陆一次 -> 更新比较时间戳
{
  "sub": "1234567890",
  "name": "John Doe",
  "iat": 1516239022
}

# iat 属性
iat是Issued At的意思，就是分发这个Token的时间

1. 每次用户登录，都检查一下当前登录的时间是否比这个分发时间晚，那就说明这次登录是已经有了这个token之后的行为2
2. 某处存储用户上次登录的时间，例如在用户的配置文件中
```

#### 解决 cookie 的问题
```bash
# cookie
cookie 太老了，而且只能存储4kb的数据，本地存储可以存储M


# 跨域问题
1. Web 应用依赖于下游服务，cookie 遵循同源策略，每个服务器都有自己的 server 方案，cookie 不容易流向下游服务器
   token 可以跨源资源共享（CORS）
   
2. cookie容易受到CSRF（跨站点请求伪造）攻击，token 只会被 xss 攻击
```

![token](https://uploader.shimo.im/f/rWkUkDiwbcgbv2hP.png!thumbnail)

#### token 的问题
```bash
# jwt的过期时间需要结合业务做设置，而且jwt一旦派发出去，后端无法强行使其作废

可以通过黑名单的方式作废，但这又违背了后端无状态的出发点（每次需要从数据库查询 token 是否作废），而且黑名单需要定期回收；
```

#
#### session 与 token

```
#
jwt不存在cookie里也就没法通过jwt做一些有关用户的服务端渲染吧？每次都要做rsa解密，性能上会不会有损失 
1. 如果是传统的session，用户量多的时候，服务器端要管理很多session，要么占内存要么用数据库，内存消耗和数据库查询都是影响性能的因素。
2. jwt，json里不要放太多东西，性能不成问题，而且让架构更简单。

jwt对服务器的压力是随着请求次数成正比的。
而session对服务器端的压力是随着用户量成正比的，即使用户不请求，只要session没有过期，就要维护这个回话


1、session认证只是把简单的User的信息存储Session里面，sessionID不可预测，一种认证手段。只存在服务端，不能共享到其他的网站和第三方App??
2、token是oAuth Token，提供的是认证和授权，认证针对用户，授权是针对App，目的就是让某APP有权访问某用户的的信息。Token是唯一的，
   token不能转移到其他的App，也不能转到其他用户上。（适用于App）???
```


#
#### 无连接
无连接的含义是限制每次连接只处理一个请求。服务器处理完客户的请求，并收到客户的应答后，即断开连接，采用这种方式可以节省传输时间。(当今多数服务器支持Keep-Alive 功能，使用服务器支持长连接，解决无连接的问题)

#### 无状态
两次连接通信之间是没有任何关系，每次都是一个新的连接，服务端不会记录前后的请求信息「不具备保存之前发送过请求或者响应的功能」

### 2.1 协议：
规定了通信双方必须遵循的「数据传输格式」，这样通信双方按照约定的格式才能准确的通信。

http 对每种需要由 web 传输的对象都打上了名为 MIME 类型的数据格式标签。主要有:

> 类型：text->[普通文本]， application->[二进制数据]

* text/html
* text/plain
* image/jpeg
* image/gif
* application/octet-stream 任意二进制文件，常用于下载
* application/x-www-form-urlencoded 浏览器的原生 <form> 表单
* video/quicktime

	
### 2.3 url( Universal Resource Locator )

uri( Universal Resource Identifier )：url 是 uri 的子集

> 统一资源定位符

#### 2.5 url 的构成

一个 URI 是由组件分隔符分割的组件序列组成：

`<scheme>://<host>「<hostname>:<port>」/<pathname><params>?<query>#<hash>`

`https://www.163.com:8080/index.html?r=admin&lang=zh-CN#news`

#
#### 2.6 url 编码与解码

> http 协议中参数传输是 `"key=value"` 这种形式 ,服务器会用 '&' 分割每一个参数，再用 '=' 分割出参数值。

**现在有一个问题，就是我的参数值中包含 '&'、'=' 这种特殊字符怎么办？解决办法就是编码呐!**

```
encodeURI「decodeURI」：接受 URI 的 protocol, host, port 等部分，只对 path 和 query 进行编码「不编码保留字符」

encodeURIComponent「decodeURIComponent」：编码你准备用作 query 一部分的字符串
```

#  
### 4. 报文格式

```bash
# 报文是HTTP通信中的基本单位，通过HTTP通信传输
# 报文 = 报文头部 + 空行 + 报文主体(可选)
报文要么是一个请求报文，要么就是一个响应报文。一次传输中，在应用层来看，就是一个传输的单位

# 实体 = 实体首部(可选) + 实体主体
实体其实是报文的一部分，存在于报文主体内，一个报文里可以包含多个实体


# "传输中需要进行编码操作", 如表单传输

POST /upload HTTP/1.1
Host: example.com
Content-Length: xxx
Content-Type: multipart/form-data; boundary=AaBbCcDd

--AaBbCcDd
Content-Disposition: form-data; name="username"

RuphiLau
--AaBbCcDd
Content-Disposition: form-data; name="file"; filename="picture.jpg"
Content-Type: image/jpeg

...(picture.jpg的数据)...
```

#### 请求

> 请求行(method url http协议) + 请求头 + 空行 +  请求主体(body)
  
![请求报文](https://github.com/CyC2018/CS-Notes/raw/master/notes/pics/HTTP_RequestMessageExample.png)

#
#### 常用方法
```
GET：获取资源

HEAD：和 GET 类似，但是不返回报文实体主体部分
  1. 确认 URL 的有效性
  2. 资源更新的日期时间
  
POST：发送「与PUT都可以新增资源，关键在于幂等性「多次提前会创建多个资源」」

PUT：上传文件
  1. 由于自身不带验证机制，任何人都可以上传文件，因此存在安全性问题，一般不使用该方法

PATCH：对资源部分修改
  1. PUT 也可以用于修改资源，但是只能完全替代原始资源，PATCH 允许部分修改

DELETE：删除文件 [与 PUT 功能相反，并且同样不带验证机制]

OPTIONS：查询指定的 URL 能够支持的方法
  1. 会返回 Allow: GET, POST, HEAD, OPTIONS 这样的内容

CONNECT：要求在与代理服务器通信时建立隧道
  1. 使用 SSL（Secure Sockets Layer，安全套接层）和 TLS（Transport Layer Security，传输层安全）协议把通信内容
     加密后经网络隧道传输。

TRACE；追踪路径 [服务器会将通信路径返回给客户端]
  1. 发送请求时，在 Max-Forwards 首部字段中填入数值，每经过一个服务器就会减 1，当数值为 0 时就停止传输。
  2. 通常不会使用 TRACE，并且它容易受到 XST 攻击（Cross-Site Tracing，跨站追踪）。
```

#
#### GET与POST的区别

```bash
# 语法是指请求响应的格式
对于HTTP（底层是TCP/IP）请求来说，比如请求第一行必须是 方法名 URI 协议/版本 这样的格式，凡是符合TCP/IP协议要求
的请求都是合法的.

也就是说 GET与POST 底层是一样的，你要给 GET 加上 request body，给 POST 带上url参数，技术上是完全行的通的。
当然，这也需要服务器支持。

# 语义则定义了这一类型的请求具有什么样的性质
比如GET的语义就是「获取资源」，POST的语义是「处理资源」，那么在具体实现这两个方法时，就必须考虑其语义，
做出符合其语义的行为。

# 以下区别都是语义上的区别

1. 作用
GET：用于获取资源，POST：用于传输实体主体

2. 参数
GET 和 POST 的请求都能使用额外的参数，GET：参数是以查询字符串出现在 URL 中，POST：参数存储在实体主体中

# 长度限制
http协议没有 body 与 url 的长度限制，对 URL 限制的大多是浏览器和服务器的原因
1. 浏览器：url 最大长度 2kb
2. 服务器：处理长 URL 要消耗比较多的资源，了性能和安全（防止恶意构造长 URL 来攻击）考虑

# 数据类型
因为 URL 只支持 ASCII 码，因此 GET 的参数中如果存在中文等字符就需要先进行编码。例如 中文 会转换为 %E4%B8%AD%E6%
，而空格会转换为 %20。POST 参数支持标准字符集。

3. 编码
GET：只能进行url编码，POST：支持多种编码方式

4. 安全
# 不能因为 POST 参数存储在实体主体中就认为它的安全性更高，因为照样可以通过一些抓包工具（Fiddler）查看。

安全的 HTTP 方法不会改变服务器状态，也就是说它只是可读的。因为 POST 的目的是传送实体主体内容，这个内容可能是用户上传的
表单数据，上传成功之后，服务器可能把这个数据存储到数据库中，因此状态也就发生了改变。
安全：HEAD、OPTIONS
不安全：PUT、DELETE

为什么 GET 没有 CSRF POST 有 CSRF，因为 GET 是获取内容，获取内容风险不大，即使伪造请求也可以通过；POST 是提交内容，不能容许伪造；严格来说 GET 也需要 CSRF。

5. 幂等性
同样的请求被执行一次与连续执行多次的效果是一样的，服务器的状态也是一样的

# 引入幂等主要是为了处理同一个请求重复发送的情况，比如在请求响应前失去连接
1. 如果方法是幂等的，就可以放心地重发一次请求。
2. 这也是浏览器在后退/刷新时遇到POST会给用户提示的原因：POST语义不是幂等的，重复请求可能会带来意想不到的后果。

6. 缓存
get 请求会被浏览器缓存
浏览器为什么缓存 GET 不缓存 POST，因为 GET 是获取现有内容，所以可以缓存，POST 是提交新内容，所以缓存毫无意义。

7. 请求
# GET产生一个TCP数据包;POST产生两个TCP数据包 [部分浏览器或框架]

GET：浏览器会把http header和data一并发送出去，服务器响应200(返回数据);
POST：浏览器先发送header，服务器响应100 continue，浏览器再发送data，服务器响应200 ok(返回数据)
# Firefox POST 只发送一次请求
```

#	
#### 响应报文

> 状态行(http协议 状态码 原因) + 响应头 + 空行 +  响应主体(body)

![响应报文](https://github.com/CyC2018/CS-Notes/raw/master/notes/pics/HTTP_ResponseMessageExample.png)


#
状态码就那些，常用的记住就行了：

#### 1XX 信息

```bash
# 部分浏览器 post 接受到 100 再发送请求实体
100 Continue ：表明到目前为止都很正常，客户端可以继续发送请求或者忽略这个响应
```

#### 2XX 成功
```
200 OK：请求已经被成功处理

204 No content：请求已经成功处理，但是返回的响应报文不包含实体的主体部分。一般在只需要从客户端往服务器发送信息，
                而不需要返回数据时使用
		
206 Partial Content：表示客户端进行了范围请求，响应报文包含由 Content-Range 指定范围的实体内容
```

#### 3XX 重定向

```
301 moved permanently：永久性重定向，表示资源已被分配了新的 URL

302 found：临时性重定向，表示资源临时被分配了新的 URL

303 see other：和 302 功能相同，但是 303 明确要求客户端应该采用 GET 方法获取资源

# 注：虽然 HTTP 协议规定 301、302 状态下重定向时不允许把 POST 方法改成 GET 方法，但是大多数浏览器都会在
  301、302 和 303 状态下的重定向把 POST 方法改成 GET 方法。

304 not modified：如果请求报文首部包含一些条件，例如：If-Match，If-None-Match，If-Modified-Since，
 		  If-Unmodified-Since，If-Range，服务器允许访问资源，但是不满足条件，则服务器会返回 304 状态码。

307 temporary redirect：临时重定向，与 302 的含义类似，但是 307 要求浏览器不会把重定向请求的 POST 方法改成 GET 方法

```

#### 4XX 客户端错误

```
400 bad request：请求报文存在语法错误

401 unauthorized：表示发送的请求需要有通过 HTTP 认证的认证信息「请求头发送 Authorization 验证」（BASIC 认证、DIGEST 认证）
		  ，如果之前已进行过一次请求，则表示用户认证失败

403 forbidden：表示对请求资源的访问被服务器拒绝「与401相反，得到授权但访问被禁」

404 not found：表示在服务器上没有找到请求的资源
```
#### 5XX 服务器错误

```
500 internal sever error：表示服务器端在执行请求时发生了错误

503 service unavailable：表明服务器暂时处于超负载或正在停机维护，无法处理请求
```

#
各种首部字段及其含义如下（不需要全记，仅供查阅）：

#### 通用首部字段
首部字段名 | 说明
------------ | -------------
Cache-Control | 控制缓存的行为
Connection | 控制不再转发给代理的首部字段、管理持久连接
Date | 创建报文的日期时间
Pragma | 报文指令
Trailer | 报文末端的首部一览
Transfer-Encoding | 指定报文主体的传输编码方式
Upgrade | 升级为其他协议
Warning | 错误通知

#
#### 请求首部字段
首部字段名 | 说明
------------ | -------------
Accept | 用户代理可处理的媒体类型
Accept-Charset | 优先的字符集
Accept-Encoding | 优先的内容编码
Accept-Language | 优先的语言（自然语言）
Authorization	Web | 认证信息
Expect | 期待服务器的特定行为
From | 用户的电子邮箱地址
Host | 请求资源所在服务器
If-Match | 比较实体标记（ETag）
If-None-Match | 比较实体标记（与 If-Match 相反）
If-Modified-Since | 比较资源的更新时间
If-Unmodified-Since | 比较资源的更新时间（与 If-Modified-Since 相反）
If-Range | 资源未更新时发送实体 Byte 的范围请求
Max-Forwards | 最大传输逐跳数
Proxy-Authorization | 代理服务器要求客户端的认证信息
Range | 实体的字节范围请求
TE | 传输编码的优先级
User-Agent | HTTP 客户端程序的信息

#
#### 响应首部字段
首部字段名 | 说明
------------ | -------------
Accept-Ranges | 是否接受字节范围请求
Age | 推算资源创建经过时间
ETag | 资源的匹配信息
Location | 令客户端重定向至指定 URI
Proxy-Authenticate | 代理服务器对客户端的认证信息
Retry-After | 对再次发起请求的时机要求
Server | HTTP 服务器的安装信息
Vary | 代理服务器缓存的管理信息
WWW-Authenticate | 服务器对客户端的认证信息

#
#### 实体首部字段
首部字段名 | 说明
------------ | -------------
Allow | 实体主体适用的编码方式
Content-Encoding | 推算资源创建经过时间
Content-Language | 实体主体的自然语言
Content-Length | 实体主体的大小
Content-Location | 替代对应资源的 URI
Content-MD5 | 实体主体的报文摘要
Content-Range | 实体主体的位置范围
Content-Type | 实体主体的媒体类型
Expires | 实体主体过期的日期时间
Last-Modified | 资源的最后修改日期时间

#  
### 三次握手与四次分手

使用 tcp 协议时，此时 Socket 连接就是 tcp 连接
	
#### TCP 首部格式

源端口号 | 目的端口号
------------ | -------------
Sequence Number(序号字段) | 对字节流进行编号 
Acknowledgment Number(确认号) | 期望收到的下一个报文段的序号
标志字段(0、1标志位) | ACK(确认) SYN(同步) FIN(终止) RST(重连)

#### 三次握手
```
seq: 连接时建立同步序号
序号为 301，表示第一个字节的编号为 301，如果携带的数据长度为 100 字节，那么下一个报文段的序号应为 401
ack: B 正确收到 A 发送来的一个报文段，序号为 501，携带的数据长度为 200 字节，因此 B 期望下一个报文段的序号为 
     701，B 发送给 A 的确认报文段中确认号就为 701

# ACK
当 ACK=1 时确认号字段有效，否则无效。TCP 规定，连接建立后所有传送的报文段 ACK=1

# SYN 
在连接建立时用来同步序号
* 连接请求报文段：SYN=1，ACK=0
* 若对方同意建立连接，响应报文中： SYN=1，ACK=1。


1. 客户端发送SYN=1（syn=x）包到服务器，并进入SYN_SENT状态，等待服务器确认；
2. 服务器收到SYN包，并确认客户端的SYN(ack=x+1)，同时自己也发送一个SYN=1包（syn=y），即SYN=1+ACK=1包，此时服务器
   进入SYN_RECV状态；
3. 客户端收到服务器的SYN+ACK包，向服务器发送ACK=1包（ack=y+1），此包发送完毕，客户端和服务器进入ESTABLISHED状态
```

#### 三次握手的原因 [不是两次或者四次]

```bash
# “为了防止已失效的连接请求报文段突然又传送到了服务端，因而产生错误”

“已失效的连接请求报文段”：
1. 客户端发出的第一个连接请求报文段并没有丢失，而是在某个网络结点长时间滞留，延误到连接释放以后的某个时间才到达服务端。
2. 本来这是一个早已失效的报文段，但服务端收到失效的连接请求报文段后，就误认为是客户端再次发出的一个新的连接请求。于是向客户端
   发出确认报文段，同意建立连接。
# 假设不用“三次握手”，那么只要服务端发出确认，新的连接就建立了

3. 现在客户端并没有发出建立连接的请求，因此不会理睬服务端的确认，也不会向服务端发送数据。但服务端却以为新的运输连接已经建立，
   并一直等待客户端发来数据。这样，服务端的很多资源就白白浪费了。

采用“三次握手”的办法可以防止上述现象发生。例如刚才那种情况，客户端不会向服务端的确认发出确认。服务端由于收不到确认，就知道客户端并没有要求建立连接。
```
	    
      
![三次握手与四次分手](https://images2015.cnblogs.com/blog/816045/201611/816045-20161105220355065-482198403.png)



	   
```
第一次握手：server 发送请求报文：SYN=1 + seq=x
第二次握手：server 收到 SYN 报文段，ACK=x+1 + seq=y,一并发送给客户端
第三次握手：client 发送 ACK 报文：ACK=y+1，完成三次握手
```
   
#### 四次挥手

tcp 是全双工模式，当主机1发出 FIN 报文段时，只是表示主机1已经没有数据要发送了，但是，这个时候主机1还是可以接受来自主机2的数据	  
```bash
1. 主机1（可以使客户端，也可以是服务器端）向主机2发送FIN(seq=x和ack=y)报文段，主机1进入FIN_WAIT_1状态；这表示主机1没有数据要发送给主机2了；
2. 主机2收到了FIN报文段，向主机1发送ACK(seq=y和ack=x+1)报文段；主机1进入FIN_WAIT_2状态；主机2告诉主机1，我“同意”你的关闭请求；
3. 主机2发送FIN报文段，请求关闭连接，同时主机2进入LAST_ACK状态；
4. 主机1收到FIN报文段，向主机2发送ACK报文段，然后主机1进入TIME_WAIT状态；主机2收到主机1的ACK报文段以后，就关闭连接;
   此时，主机1等待2MSL（一来一回）后依然没有收到回复，则证明主机2已正常关闭，那好，主机1也可以关闭连接了

# MSL是任何IP数据报能够在因特网中存活的最长时间。TIME_WAIT状态使得客户机重传最终确认报文，以防ACK丢失


注意点：
1.FIN_WAIT_1和FIN_WAIT_2状态的真正含义都是表示等待对方的FIN报文, FIN_WAIT_2表示半连接

2.TIME_WAIT：状态使得客户机重传最终确认报文，以防ACK丢失

执行主动关闭的那端经历了这个状态。该端点停留在这个状态的持续时间是最长分节生命期（maximum segment lifetime, MSL）
的两倍，有时候称为2MSL。MSL是任何IP数据报能够在因特网中存活的最长时间。

 
# TIME_WAIT存在的理由
1.可靠地实现TCP全双工连接的停止 [确保最后一个确认报文能够到达]

(1)（client）最后发送的ACK在网络中丢失，由于TCP协议的重传机制，执行被动关闭的一方（server）将会重发其FIN
   
(2)在该FIN到达client之前，client必须维护这条连接状态，也就说这条TCP连接所对应的资源（client方的local_ip,
   local_port）不能被立即释放或重新分配，直到另一方重发的FIN达到之后，client重发ACK后，经过2MSL时间周期没
   有再收到另一方的FIN之后，该TCP连接才能恢复初始的CLOSED状态。如果不维护这样一个TIME_WAIT状态，重发的FIN到
   达时，client TCP传输层会用RST(reset重连)包响应对方，这会被对方认为是有异常发生，

2.允许老的重复分节在网络中消逝
问题：TCP报文可能由于路由器异常而“迷途”，在迷途期间，TCP发送端可能因确认超时而重发这个报文，迷途的报文在路由器修复后
也会被送到最终目的地，这个迟到的迷途分节到达时可能会引起问题。

(1)在关闭“前一个连接”之后，马上又重新建立起一个相同的IP和端口之间的“新连接”，“前一个连接”的迷途重复分组在“前一个连接”
终止后到达，而被“新连接”收到了。
(2)TCP不允许TIME_WAIT状态的连接启动一个新的可用连接，因为TIME_WAIT状态持续2MSL，就可以保证当成功建立一个新TCP连接
的时候，来自旧连接重复分组已经在网络中消逝。
```

	      
	
#
### http 的发展
#### 1. http/1.0 与 http/1.1「头信息必须是 ASCII 码，后面的数据可以是任何格式」

> 每个 http 请求都要求打开一个 tpc socket 连接，并且使用一次之后就断开这个 tcp 连接

http/1.0 的缺点：每个 TCP 连接只能发送一个请求。发送数据完毕，连接就关闭，如果还要请求其他资源，就必须再新建一个连接
	  
#### 2. http/1.1 即引入了持久连接

**2.1 持久连接**

> connection: keep-alive

在一次 TCP 连接中可以持续发送多份数据而不会断开连接。这意味着可以减少 tcp 连接建立次数，也意味着可以减少 TIME_WAIT 状态连接，以此提高性能和提高 http 服务器的吞吐率「更少的 tcp 连接意味着更少的系统内核调用, socket 的 accept() 和 close() 调用」

但是，keep-alive 并不是免费的午餐,长时间的 tcp 连接容易导致系统资源无效占用。配置不当的 keep-alive，有时比重复利用连接带来的损失还更大。所以，正确地设置 keep-alive timeout 时间非常重要。

HTTP 长连接不可能一直保持，例如 `Keep-Alive: timeout=5, max=100` ，表示这个TCP通道可以保持5秒，max=100，表示这个长连接最多接收100次请求就断开


**2.2 长连接判断传输结束**

由 `keep-alive` 引入了 `Content-length` 和 `chunked`
```
// 因为 tcp 可以回传多个协议，一种区分数据包属于哪个回应的机制「声明数据长度」
Content-length // 需要等待耗时操作完成
Transfer-Encoding: chunked // 产生一块数据就发送一块

header 引入：
Connection: keep-alive「close」 // TCP 连接默认不关闭，可以被多个请求复用「close；响应完成后，关闭连接」

Host: www.example.com // 有了 Host 字段，就可以将请求发往同一台服务器上的不同网站，为虚拟主机的兴起打下了基础
```

**2.2 管道机制**

> 并发多个请求需要使用多个 tcp 连接「但服务器还是按照顺序，先回应 A 请求，完成后再回应 B 请求」

TCP的3次握手和四次挥手；TCP与UDP的区别

HTTP协议；HTTP1.0与2.0的区别；HTTP报文结构

HTTP与HTTPS的区别以及如何实现安全性
	  
#### 3. http/2「二进制协议」

> SPDY位于HTTP之下，TCP和SSL之上

SPDY：

1. 多路复用
1. 请求优先级「连接共享的基础之上有可能会导致关键请求被阻塞。SPDY允许给每个request设置优先级，这样重要的请求就会优先得到响应」
1. header压缩
1. 基于HTTPS的加密协议传输
1. 服务端推送


HTTP1.0：头信息必须是 ASCII 码，后面的数据可以是任何格式
http/2：头信息+数据体 都是二进制「统称为帧」，不用考虑很多场景
	  
数据流：每个请求或回应的所有数据包，称为一个数据流「都有独一无二的 Id 进行区分」

**http/2 即引入了多路复用（Multiplexing）**[双向的、实时的通信, 基于SPDY，但是支持明文 HTTP 传输]

即每一个 request 都是是用作连接共享机制的。一个 request 对应一个 id，这样一个连接上可以有多个 request，每个连接的 request 可以随机的混杂在一起，接收方可以根据 id 将 request 进行区分
	    
头信息压缩：http1 header 带有大量信息而且需要重复发送，http2 客户端服务器同时维护了一张字段表，发送索引即可。

服务器推送：主动向客户端发送预期可能请求资源

#
### https

#### http 存在的问题

* http 报文使用明文方式传输发送，所有发送和接收经过某些设备的数据都可能被截获或窥视
* HTTPS协议是由 SSL+HTTP 协议构建的可进行加密传输、身份认证的网络协议，数据不被窃取、改变「保证数据完整性」「大幅增加中间人攻击成本」

但是：

* https 握手当然比较费时啦，又增加了一层 安全传输协议 的握手过程「页面加载时间延长~~~」
* 不能在同一 ip 上绑定多个域名「SSL 需要绑定 ip」

#### 1. 对称加密

Q: 约定一个随机生成的密钥，使用同样的密钥进行加密解密

A: 第一次约定加密方式和密钥的通信仍是明文，中间人仍可解密

#
#### 2. 非对称加密

Q:
1. server 发送自己的公钥 key1, client 收到后生成对称加密密钥 key2，并用刚才收到 公钥 key1 对 key2 进行加密， 发送给 server

2. server 非对称私钥，解开公钥 key1 加密获得 key2 内容，server 与 client 通过 key2(对称加密) 通信

A: 虽然无法获取私钥「替换公钥轻松 solve」

#
#### 引入第三方证书机构

> SSL/TSL: 就是在**!传输层**上加了一层 SSL(socket security layer) / TSL (transport security layer)「使用了非对称加密，对称加密以及 HASH  算法」

> 公钥「在数字证书中」和私钥只用于加「解」密对话密钥「由 随机数 生成」

> 起始随机数都是 Client 发送「只有最后一个非明文」

HTTPS 在传输数据之前需要客户端与服务端之间进行一次握手过程：

1. 浏览器将自己支持的一套加密规则、随机数发送给 server

1. server 从中选出一组加密算法，并将证书、随机数发回给浏览器。证书信息：「机构私钥加密：网站地址，加密公钥，以及证书的颁发机构等信息。」

1. 获得网站证书之后浏览器要做以下工作：
    1. 验证证书的合法性「浏览器和OS已经维护了所有权威证书机构的名称和公钥」
    1. 证书受信或用户接受不受信证书：发送公钥加密的随机数 
    
1. server 获取随机数，生成对话密钥并进行对话

#
## 缓存

> 未命中缓存策略，从服务器重新加载资源时，会更新 header 缓存相关字段

#### 响应缓存条件

```
# HTTP 方法本身是可缓存的
包括 GET 和 HEAD，但是 PUT 和 DELETE 不可缓存，POST 在多数情况下不可缓存的

# 状态码是可缓存的
包括：200, 203, 204, 206, 300, 301, 404, 405, 410, 414, and 501。

# 响应报文的 Cache-Control 首部字段没有指定不进行缓存

```

### 强制缓存

> 服务器和浏览器约定资源过期时间

为静态资源全部配置一个超时时间超长的 Expires 或 Cache-Control

#### 1. Cache-Control「秒为单位」

> 响应是否可缓存到 client

http/1.1
```
Cache-Control: public [仅 User-Agent]、private
no-cache [不建议本地缓存]
max-age：缓存周期
no-store [不会缓存到客户端] 

Cache-Control: max-age [存储+过期策略]
// 实际上相当于
Cache-Control: public/private（这里不太确定具体哪个）
Expires：当前客户端时间 + maxAge

Cache-Control：no-cache [存储+过期策略]
// 相当于
Cache-Control：max-age=0 （单位是秒）
```

#### 2. Expires「日期」

#### Cache-Control 中过期策略优先级更高

> Expires：确认在本地缓存数据是否过期，进而决定是否请求服务器端

> Expires: server 系统的绝对时间「万一服务器与 client 时间差比较大呢」

缓存数据标记为已过期只是告诉客户端不能再直接从本地读取缓存了，需要再发一次请求到服务器去确认「协商缓存」，并不等同于本地缓存数据从此就没用了

http/1.0
```
// 同时存在更高优先级
Cache-Control

// 启发式缓存过期策略 [未提供任何过期策略]
Expires = （Date - Last-Modified）* 10%
```

#### 强缓存应用

解决资源更新问题：

> 我们只对 html 文件动一动手脚，html 中请求的资源我们进行缓存

由于过期时间独自无法解决快速更新的问题，条件请求也无法避免发送一次请求。 MD5 + 永不过期的 CDN 几乎已经成为业界常态：为每一个静态文件的文件名都增加版本号（或 MD5 值）， 每次更新文件都同时更新版本号，每个文件都在Cache-Control设为永不过期， 同时 HTML 等入口文件的 Cache-Control 则设为禁止缓存!


1. 通过更新页面中引用的资源路径，让浏览器主动放弃缓存，加载新资源

```
<link rel="stylesheet" href="a.css?v1.0">  ->  <link rel="stylesheet" href="a.css?v1.1">
<link rel="stylesheet" href="b.css?v1.0">  ->  <link rel="stylesheet" href="b.css?v1.1">
```

但是我们只更新了 a.css，要是导致其他缓存失效，是不是很影响性能、浪费带宽...

2. url 与文件内容级联

> 使用webpack打包的话，借助插件可以很方便的处理。

数据摘要算法

```
<link rel="stylesheet" href="a.css?8f9hfk>
<link rel="stylesheet" href="b.css?h3ff78">
```

### 3. 协商缓存 

> 服务器告诉浏览器资源上次修改时间

> 解决强制缓存过期后，无论静态资源是否变化，都需要再次下载

一般都是 Last-Modified 与 Etag 同时启用

#### 1. Last-Modified

> 将缓存在本地数据请求服务器，服务器判断本地缓存数据是否有效「和服务器最近修改时间对比」，进而决定是否重发数据。

Last-Modified：使用服务器时间，但可能出现服务器上资源有变化，但是修改时间没变「难定位」「很影响协商缓存的可靠性」, 所以出现了另一对 header 管理协商缓存

#### 2. Etag

> 继续改进，增加文件对比内容

ETag：资源本身会随时变动「根据当前请求资源生成的唯一标识」

```
response                                          request

# 高优先级
Etag                                   <=>    If-None-Watch [版本号]「动态内容」

Last-Modified「304 不返回该字段：未更新」  <=>    If-Modified-Since [指定日期后修改?]「文件服务」
```

Q:为什么有了 ETag，还要用 Last-Modified？

* 1.两者互补，ETag 的判断的缺陷，比如一些图片等静态文件的修改 
* 2.如果每次扫描内容都生成 ETag 比较，显然要比直接比较修改时间慢的多


#
如果资源已经被浏览器缓存下来，在缓存失效之前，再次请求时，默认会先检查是否命中强缓存，如果强缓存命中则直接读取缓存，如果强缓存没有命中则发请求到服务器检查是否命中协商缓存，如果协商缓存命中，则告诉浏览器还是可以从缓存读取，否则才从服务器返回最新的资源。这是默认的处理方式，这个方式可能被浏览器的行为改变：

1）当ctrl+f5强制刷新网页时，直接从服务器加载，跳过强缓存和协商缓存；

2）当f5刷新网页时，跳过强缓存，但是会检查协商缓存；



